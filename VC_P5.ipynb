{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paquetes necesarios para el código",
   "id": "28c98d0a8e12da74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T21:32:47.070029Z",
     "start_time": "2024-11-12T21:32:45.931520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ],
   "id": "a59f0e2704b20415",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Configuración de Mediapipe y prueba con la webcam",
   "id": "4e0909bac158270f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:27:31.254412Z",
     "start_time": "2024-11-12T22:27:17.501775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicializamos MediaPipe para detección de rostros\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)  # Usa la cámara predeterminada\n",
    "\n",
    "while True:\n",
    "    # Capturamos el fotograma de la webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertimos el fotograma a RGB (requisito para MediaPipe)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(rgb_frame)\n",
    "\n",
    "    # Verificamos si se ha detectado alguna cara\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            # Obtenemos la caja delimitadora de la cara\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            h, w, _ = frame.shape\n",
    "            x, y, width, height = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)\n",
    "\n",
    "            # Dibujamos el rectángulo alrededor de la cara\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "            # Dibujamos los puntos clave (MediaPipe ofrece 6 puntos clave en detección de rostro)\n",
    "            for keypoint in detection.location_data.relative_keypoints:\n",
    "                keypoint_x = int(keypoint.x * w)\n",
    "                keypoint_y = int(keypoint.y * h)\n",
    "                cv2.circle(frame, (keypoint_x, keypoint_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Mostramos el fotograma con las detecciones\n",
    "    cv2.imshow(\"MediaPipe Face Detection\", frame)\n",
    "    \n",
    "    # Para salir, pulsa la tecla \"q\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Liberamos los recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "94f2cfc1ce09ec5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creación del filtro del perro de snapchat",
   "id": "4bf800f43e8f683b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T22:43:20.057276Z",
     "start_time": "2024-11-12T22:42:50.112639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicializamos MediaPipe para detección de rostros\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=3, min_detection_confidence=0.5)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Carga las imágenes PNG\n",
    "dog_ears = cv2.imread(\"assets/dog_ears.png\", -1)\n",
    "dog_nose = cv2.imread(\"assets/dog_nose.png\", -1)\n",
    "dog_tongue = cv2.imread(\"assets/dog_tongue.png\", -1)\n",
    "\n",
    "dalmatian_ears = cv2.imread(\"assets/dalmatian_ears.png\", -1)\n",
    "dalmatian_nose = cv2.imread(\"assets/dalmatian_nose.png\", -1)\n",
    "\n",
    "def overlay_image(background, overlay, x, y, w, h):\n",
    "    if x < 0:\n",
    "        overlay = overlay[:, -x:]  # Recortamos el borde izquierdo de overlay si está fuera del marco\n",
    "        w += x  # Ajustamos el ancho\n",
    "        x = 0\n",
    "    if y < 0:\n",
    "        overlay = overlay[-y:, :]  # Recortamos el borde superior de overlay si está fuera del marco\n",
    "        h += y  # Ajustamos la altura\n",
    "        y = 0\n",
    "    if x + w > background.shape[1]:\n",
    "        w = background.shape[1] - x  # Ajustamos el ancho si está fuera del borde derecho\n",
    "    if y + h > background.shape[0]:\n",
    "        h = background.shape[0] - y  # Ajustamos la altura si está fuera del borde inferior\n",
    "\n",
    "    # Verificar que w y h sean positivos\n",
    "    if w <= 0 or h <= 0:\n",
    "        return background  # No aplicamos el overlay si las dimensiones no son válidas\n",
    "\n",
    "    overlay = cv2.resize(overlay, (w, h))\n",
    "    alpha_overlay = overlay[:, :, 3] / 255.0\n",
    "    alpha_background = 1.0 - alpha_overlay\n",
    "\n",
    "    for c in range(3):  # Para cada canal de color (BGR)\n",
    "        background[y:y + h, x:x + w, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                                           alpha_background * background[y:y + h, x:x + w, c])\n",
    "    return background\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertir el frame a RGB (requisito para MediaPipe)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for i, face_landmarks in enumerate(results.multi_face_landmarks):\n",
    "            h, w, _ = frame.shape\n",
    "\n",
    "            # Obtener posiciones de puntos clave para colocar los elementos\n",
    "            left_eye = face_landmarks.landmark[33]  # Punto sobre el ojo izquierdo\n",
    "            right_eye = face_landmarks.landmark[263]  # Punto sobre el ojo derecho\n",
    "            nose = face_landmarks.landmark[1]  # Punto de la nariz\n",
    "            mouth_top = face_landmarks.landmark[13]  # Punto superior de la boca\n",
    "            mouth_bottom = face_landmarks.landmark[14]  # Punto inferior de la boca\n",
    "\n",
    "            # Convertir coordenadas normalizadas a píxeles\n",
    "            left_eye = (int(left_eye.x * w), int(left_eye.y * h))\n",
    "            right_eye = (int(right_eye.x * w), int(right_eye.y * h))\n",
    "            nose = (int(nose.x * w), int(nose.y * h))\n",
    "            mouth_top = (int(mouth_top.x * w), int(mouth_top.y * h))\n",
    "            mouth_bottom = (int(mouth_bottom.x * w), int(mouth_bottom.y * h))\n",
    "\n",
    "            eye_distance = abs(right_eye[0] - left_eye[0])\n",
    "            ear_width = int(eye_distance * 2.5)  # Ajuste del ancho de las orejas\n",
    "            nose_width = eye_distance // 2\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                ear_height = int(ear_width * dog_ears.shape[0] / dog_ears.shape[1])\n",
    "                frame = overlay_image(frame, dog_ears, left_eye[0] - ear_width // 4, left_eye[1] - ear_height, ear_width,\n",
    "                                      ear_height)\n",
    "\n",
    "                nose_height = int(nose_width * dog_nose.shape[0] / dog_nose.shape[1])\n",
    "                frame = overlay_image(frame, dog_nose, nose[0] - nose_width // 2, nose[1] - nose_height // 2, nose_width,\n",
    "                                      nose_height)\n",
    "\n",
    "            else:\n",
    "                ear_height = int(ear_width * dalmatian_ears.shape[0] / dalmatian_ears.shape[1])\n",
    "                frame = overlay_image(frame, dalmatian_ears, left_eye[0] - ear_width // 4, left_eye[1] - ear_height,\n",
    "                                      ear_width, ear_height)\n",
    "\n",
    "                nose_height = int(nose_width * dalmatian_nose.shape[0] / dalmatian_nose.shape[1])\n",
    "                frame = overlay_image(frame, dalmatian_nose, nose[0] - nose_width // 2, nose[1] - nose_height // 2,\n",
    "                                      nose_width,\n",
    "                                      nose_height)\n",
    "\n",
    "            # Detectar si la boca está abierta y colocar la lengua\n",
    "            mouth_opening_height = abs(mouth_bottom[1] - mouth_top[1])\n",
    "            mouth_open_threshold = h / 20  # Ajustar este umbral según sea necesario\n",
    "            if mouth_opening_height > mouth_open_threshold:\n",
    "                tongue_width = nose_width * 2\n",
    "                tongue_height = int(tongue_width * dog_tongue.shape[0] / dog_tongue.shape[1])\n",
    "                frame = overlay_image(frame, dog_tongue, nose[0] - tongue_width // 2, mouth_bottom[1], tongue_width,\n",
    "                                      tongue_height * 2)\n",
    "\n",
    "    cv2.imshow(\"Filtro Snapchat\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "7d77f02e2dbe029",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
