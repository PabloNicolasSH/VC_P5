{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Paquetes necesarios para el código",
   "id": "28c98d0a8e12da74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T21:32:47.070029Z",
     "start_time": "2024-11-12T21:32:45.931520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ],
   "id": "a59f0e2704b20415",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Configuración de Mediapipe y prueba con la webcam",
   "id": "4e0909bac158270f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T21:33:24.907989Z",
     "start_time": "2024-11-12T21:32:48.773177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicializamos MediaPipe para detección de rostros\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)  # Usa la cámara predeterminada\n",
    "\n",
    "while True:\n",
    "    # Capturamos el fotograma de la webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convertimos el fotograma a RGB (requisito para MediaPipe)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_detection.process(rgb_frame)\n",
    "\n",
    "    # Verificamos si se ha detectado alguna cara\n",
    "    if results.detections:\n",
    "        for detection in results.detections:\n",
    "            # Obtenemos la caja delimitadora de la cara\n",
    "            bboxC = detection.location_data.relative_bounding_box\n",
    "            h, w, _ = frame.shape\n",
    "            x, y, width, height = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)\n",
    "\n",
    "            # Dibujamos el rectángulo alrededor de la cara\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "            # Dibujamos los puntos clave (MediaPipe ofrece 6 puntos clave en detección de rostro)\n",
    "            for keypoint in detection.location_data.relative_keypoints:\n",
    "                keypoint_x = int(keypoint.x * w)\n",
    "                keypoint_y = int(keypoint.y * h)\n",
    "                cv2.circle(frame, (keypoint_x, keypoint_y), 5, (0, 0, 255), -1)\n",
    "\n",
    "    # Mostramos el fotograma con las detecciones\n",
    "    cv2.imshow(\"MediaPipe Face Detection\", frame)\n",
    "    \n",
    "    # Para salir, pulsa la tecla \"q\"\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Liberamos los recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "94f2cfc1ce09ec5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creación del filtro del perro de snapchat",
   "id": "4bf800f43e8f683b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T19:55:38.258108Z",
     "start_time": "2024-11-12T19:55:23.438982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicializamos MTCNN para detección de rostros\n",
    "detector = MTCNN()\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "# Carga las imágenes PNG con fondo transparente\n",
    "dog_ears = cv2.imread(\"assets/dog_ears.png\", -1)\n",
    "dog_nose = cv2.imread(\"assets/dog_nose.png\", -1)\n",
    "dog_tongue = cv2.imread(\"assets/dog_tongue.png\", -1)\n",
    "\n",
    "def overlay_image(background, overlay, x, y, w, h):\n",
    "    overlay = cv2.resize(overlay, (w, h))\n",
    "    alpha_overlay = overlay[:, :, 3] / 255.0\n",
    "    alpha_background = 1.0 - alpha_overlay\n",
    "    \n",
    "    for c in range(3):  # Para cada canal de color (BGR)\n",
    "        background[y:y+h, x:x+w, c] = (alpha_overlay * overlay[:, :, c] +\n",
    "                                       alpha_background * background[y:y+h, x:x+w, c])\n",
    "    return background\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detectar cara y puntos clave\n",
    "    results = detector.detect_faces(frame)\n",
    "\n",
    "    for result in results:\n",
    "        keypoints = result[\"keypoints\"]\n",
    "        x, y, width, height = result[\"box\"]\n",
    "        \n",
    "        if y is None:\n",
    "            continue\n",
    "        # Poner las orejas sobre la cabeza\n",
    "        ear_width = width  # Ajustamos el ancho de las orejas al ancho de la cara\n",
    "        ear_height = int(ear_width * dog_ears.shape[0] / dog_ears.shape[1])  # Mantener proporción de la imagen\n",
    "        frame = overlay_image(frame, dog_ears, x, y - ear_height // 2, ear_width, ear_height)\n",
    "\n",
    "        # Poner la nariz sobre la nariz\n",
    "        nose_width = width // 3\n",
    "        nose_height = int(nose_width * dog_nose.shape[0] / dog_nose.shape[1])\n",
    "        frame = overlay_image(frame, dog_nose, keypoints[\"nose\"][0] - nose_width // 2, \n",
    "                              keypoints[\"nose\"][1] - nose_height // 2, nose_width, nose_height)\n",
    "\n",
    "        # Detectar si la boca está abierta y colocar la lengua\n",
    "        mouth_left = keypoints[\"mouth_left\"]\n",
    "        mouth_right = keypoints[\"mouth_right\"]\n",
    "        \n",
    "        # Calculamos el centro de la boca\n",
    "        mouth_center_x = (mouth_left[0] + mouth_right[0]) // 2\n",
    "        mouth_center_y = (mouth_left[1] + mouth_right[1]) // 2\n",
    "\n",
    "        # Calculamos la distancia entre la nariz y el centro de la boca\n",
    "        nose_to_mouth_distance = np.linalg.norm(np.array(keypoints[\"nose\"]) - np.array([mouth_center_x, mouth_center_y]))\n",
    "\n",
    "        # Establecemos un umbral para la apertura de la boca\n",
    "        mouth_open_threshold = height / 3\n",
    "        if nose_to_mouth_distance > mouth_open_threshold:\n",
    "            tongue_width = nose_width  # Usamos el ancho de la nariz para mantener una escala adecuada\n",
    "            tongue_height = int(tongue_width * dog_tongue.shape[0] / dog_tongue.shape[1])\n",
    "            frame = overlay_image(frame, dog_tongue, mouth_center_x - tongue_width // 2, \n",
    "                                  mouth_center_y, tongue_width, tongue_height)\n",
    "\n",
    "    # Mostramos el fotograma con el filtro aplicado\n",
    "    cv2.imshow(\"Dog Filter with Open Mouth Detection\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "7d77f02e2dbe029",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (68,194) (0,194) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 37\u001B[0m\n\u001B[0;32m     35\u001B[0m ear_width \u001B[38;5;241m=\u001B[39m width  \u001B[38;5;66;03m# Ajustamos el ancho de las orejas al ancho de la cara\u001B[39;00m\n\u001B[0;32m     36\u001B[0m ear_height \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(ear_width \u001B[38;5;241m*\u001B[39m dog_ears\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m/\u001B[39m dog_ears\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])  \u001B[38;5;66;03m# Mantener proporción de la imagen\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m frame \u001B[38;5;241m=\u001B[39m overlay_image(frame, dog_ears, x, y \u001B[38;5;241m-\u001B[39m ear_height \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, ear_width, ear_height)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# Poner la nariz sobre la nariz\u001B[39;00m\n\u001B[0;32m     40\u001B[0m nose_width \u001B[38;5;241m=\u001B[39m width \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m3\u001B[39m\n",
      "Cell \u001B[1;32mIn[3], line 17\u001B[0m, in \u001B[0;36moverlay_image\u001B[1;34m(background, overlay, x, y, w, h)\u001B[0m\n\u001B[0;32m     13\u001B[0m alpha_background \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m alpha_overlay\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):  \u001B[38;5;66;03m# Para cada canal de color (BGR)\u001B[39;00m\n\u001B[0;32m     16\u001B[0m     background[y:y\u001B[38;5;241m+\u001B[39mh, x:x\u001B[38;5;241m+\u001B[39mw, c] \u001B[38;5;241m=\u001B[39m (alpha_overlay \u001B[38;5;241m*\u001B[39m overlay[:, :, c] \u001B[38;5;241m+\u001B[39m\n\u001B[1;32m---> 17\u001B[0m                                    alpha_background \u001B[38;5;241m*\u001B[39m background[y:y\u001B[38;5;241m+\u001B[39mh, x:x\u001B[38;5;241m+\u001B[39mw, c])\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m background\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (68,194) (0,194) "
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
